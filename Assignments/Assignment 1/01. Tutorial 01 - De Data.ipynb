{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0681af7",
   "metadata": {},
   "source": [
    "# Tutorial 1: De Data Practical Sheet 1\n",
    "\n",
    "---\n",
    "\n",
    "Name: Adam Ryan\n",
    "\n",
    "DC: 2021-09-23\n",
    "\n",
    "DLM: 2021-09-23\n",
    "\n",
    "Desc: This notebook is to capture the solution which will be used for the report for Tutorial Sheet 1 as part of the Text Analytics module. This sheet involves processing a data set.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "53e52202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import num2words\n",
    "import regex as re\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bdaf4d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file=open('text-file.txt')\n",
    "text_from_file=text_file.read()\n",
    "text_from_file='Sentences like ‘Buffalo buffalo Buffalo buffalo buffalo buffalo Buffalo buffalo‘ which demonstrate lexical ambiguity are ones I’d 100% expect text parsers to have difficulty with. Phrases involving colloquialisms from the R.O.I’d also be tough to intepret like ‘what’s the craic’, ‘I’m absolutely stuffed’, or ‘thats gas’; all are Irish expressions.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7adbb019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_text(raw_text):\n",
    "    lower_text = raw_text.lower()\n",
    "    print(lower_text)\n",
    "    \n",
    "    lower_text_no_contractions = (lower_text\n",
    "                                 .replace('’',\"'\")\n",
    "                                 .replace('‘',\"'\")\n",
    "                                  .replace('’',\"'\")\n",
    "                                  .replace(\"'m\",\" am\")\n",
    "                                 .replace(\"ain't\",'am not')\n",
    "                                 .replace(\"can't\",'can not')\n",
    "                                 .replace(\"cannot\",'can not')\n",
    "                                  .replace(\"'ll\", \" will\")\n",
    "                                  .replace(\"'ve\", \"  have\")\n",
    "                                  .replace(\"'d\", \"  would\")\n",
    "                                  .replace(\"'s\", \"  is\")\n",
    "                                  .replace(\"n't\", \" not\")\n",
    "                                  .replace(\"'re\",'are'))\n",
    "    \n",
    "    \n",
    "    lower_text_no_contractions_no_punctuation = (lower_text_no_contractions\n",
    "                          .replace(\",\", \"\")\n",
    "                          .replace(\"'\", \"\")\n",
    "                          .replace('\"', \"\")\n",
    "                          .replace(\";\", \"\")\n",
    "                          .replace(\".\",\"\")\n",
    "                          .replace('’','')\n",
    "                          .replace('‘','')\n",
    "                          .replace(\"%\",\" percent\")\n",
    "                          .replace(\"percentage\",\"percent\"))\n",
    "\n",
    "\n",
    "    lower_text_no_contractions_no_punctuation_no_digits = re.sub(r\"(\\d+)\", lambda x: num2words.num2words(int(x.group(0))), lower_text_no_contractions_no_punctuation)\n",
    "\n",
    "\n",
    "    \n",
    "    tokens = nltk.word_tokenize(lower_text_no_contractions_no_punctuation_no_digits)\n",
    "    filtered_text = [non_stop_word for non_stop_word in tokens if not non_stop_word in set(nltk.corpus.stopwords.words('english'))]\n",
    "    print(filtered_text)\n",
    "    \n",
    "    \n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "015f6e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tag_text(text):\n",
    "    \n",
    "    \n",
    "    pos_dict={'CC':'Coordinating conjunction',\n",
    "            'CD':'Cardinal number',\n",
    "            'DT':'Determiner',\n",
    "            'EX':'Existential there',\n",
    "            'FW':'Foreign word',\n",
    "            'IN':'Preposition or subordinating conjunction',\n",
    "            'JJ':'Adjective',\n",
    "            'JJR':'Adjective, comparative',\n",
    "            'JJS':'Adjective, superlative',\n",
    "            'LS':'List item marker',\n",
    "            'MD':'Modal',\n",
    "            'NN':'Noun, singular or mass',\n",
    "            'NNS':'Noun, plural',\n",
    "            'NNP':'Proper noun, singular',\n",
    "            'NNPS':'Proper noun, plural',\n",
    "            'PDT':'Predeterminer',\n",
    "            'POS':'Possessive ending',\n",
    "            'PRP':'Personal pronoun',\n",
    "            'PRP$':'Possessive pronoun',\n",
    "            'RB':'Adverb',\n",
    "            'RBR':'Adverb, comparative',\n",
    "            'RBS':'Adverb, superlative',\n",
    "            'RP':'Particle',\n",
    "            'SYM':'Symbol',\n",
    "            'TO':'to',\n",
    "            'UH':'Interjection',\n",
    "            'VB':'Verb, base form',\n",
    "            'VBD':'Verb, past tense',\n",
    "            'VBG':'Verb, gerund or present participle',\n",
    "            'VBN':'Verb, past participle',\n",
    "            'VBP':'Verb, non-3rd person singular present',\n",
    "            'VBZ':'Verb, 3rd person singular present',\n",
    "            'WDT':'Wh-determiner',\n",
    "            'WP':'Wh-pronoun',\n",
    "            'WP$':'Possessive wh-pronoun',\n",
    "            'WRB':'Wh-adverb'}\n",
    "\n",
    "    tagged_text=nltk.pos_tag(text)\n",
    "    \n",
    "    tagged_text_mod=[]\n",
    "    \n",
    "    for word_pair in tagged_text:\n",
    "        entry_pair=()\n",
    "        entry_pair=(word_pair[0],pos_dict[word_pair[1]])\n",
    "        tagged_text_mod+=[entry_pair]\n",
    "    \n",
    "    return tagged_text_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ef6a5cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentences like ‘buffalo buffalo buffalo buffalo buffalo buffalo buffalo buffalo‘ which demonstrate lexical ambiguity are ones i’d 100% expect text parsers to have difficulty with. phrases involving colloquialisms from the r.o.i’d also be tough to intepret like ‘what’s the craic’, ‘i’m absolutely stuffed’, or ‘thats gas’; all are irish expressions.\n",
      "['sentences', 'like', 'buffalo', 'buffalo', 'buffalo', 'buffalo', 'buffalo', 'buffalo', 'buffalo', 'buffalo', 'demonstrate', 'lexical', 'ambiguity', 'ones', 'would', 'one', 'hundred', 'percent', 'expect', 'text', 'parsers', 'difficulty', 'phrases', 'involving', 'colloquialisms', 'roi', 'would', 'also', 'tough', 'intepret', 'like', 'craic', 'absolutely', 'stuffed', 'thats', 'gas', 'irish', 'expressions']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sentences',\n",
       " 'like',\n",
       " 'buffalo',\n",
       " 'buffalo',\n",
       " 'buffalo',\n",
       " 'buffalo',\n",
       " 'buffalo',\n",
       " 'buffalo',\n",
       " 'buffalo',\n",
       " 'buffalo',\n",
       " 'demonstrate',\n",
       " 'lexical',\n",
       " 'ambiguity',\n",
       " 'ones',\n",
       " 'would',\n",
       " 'one',\n",
       " 'hundred',\n",
       " 'percent',\n",
       " 'expect',\n",
       " 'text',\n",
       " 'parsers',\n",
       " 'difficulty',\n",
       " 'phrases',\n",
       " 'involving',\n",
       " 'colloquialisms',\n",
       " 'roi',\n",
       " 'would',\n",
       " 'also',\n",
       " 'tough',\n",
       " 'intepret',\n",
       " 'like',\n",
       " 'craic',\n",
       " 'absolutely',\n",
       " 'stuffed',\n",
       " 'thats',\n",
       " 'gas',\n",
       " 'irish',\n",
       " 'expressions']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalised_text=normalise_text(text_from_file)\n",
    "normalised_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9cc9e55e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sentences', 'Noun, plural'),\n",
       " ('like', 'Preposition or subordinating conjunction'),\n",
       " ('buffalo', 'Noun, singular or mass'),\n",
       " ('buffalo', 'Noun, singular or mass'),\n",
       " ('buffalo', 'Noun, singular or mass'),\n",
       " ('buffalo', 'Noun, singular or mass'),\n",
       " ('buffalo', 'Noun, singular or mass'),\n",
       " ('buffalo', 'Noun, singular or mass'),\n",
       " ('buffalo', 'Noun, singular or mass'),\n",
       " ('buffalo', 'Noun, singular or mass'),\n",
       " ('demonstrate', 'Verb, base form'),\n",
       " ('lexical', 'Adjective'),\n",
       " ('ambiguity', 'Noun, singular or mass'),\n",
       " ('ones', 'Noun, plural'),\n",
       " ('would', 'Modal'),\n",
       " ('one', 'Cardinal number'),\n",
       " ('hundred', 'Cardinal number'),\n",
       " ('percent', 'Noun, singular or mass'),\n",
       " ('expect', 'Verb, non-3rd person singular present'),\n",
       " ('text', 'Noun, singular or mass'),\n",
       " ('parsers', 'Noun, plural'),\n",
       " ('difficulty', 'Verb, non-3rd person singular present'),\n",
       " ('phrases', 'Noun, plural'),\n",
       " ('involving', 'Verb, gerund or present participle'),\n",
       " ('colloquialisms', 'Noun, plural'),\n",
       " ('roi', 'Noun, singular or mass'),\n",
       " ('would', 'Modal'),\n",
       " ('also', 'Adverb'),\n",
       " ('tough', 'Adjective'),\n",
       " ('intepret', 'Noun, singular or mass'),\n",
       " ('like', 'Preposition or subordinating conjunction'),\n",
       " ('craic', 'Noun, singular or mass'),\n",
       " ('absolutely', 'Adverb'),\n",
       " ('stuffed', 'Verb, past tense'),\n",
       " ('thats', 'Noun, plural'),\n",
       " ('gas', 'Noun, singular or mass'),\n",
       " ('irish', 'Adjective'),\n",
       " ('expressions', 'Noun, plural')]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a7f2f39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Brown Thomas and Arnotts (BTA) are too Irish companies, operating 7 physical shops, which were purchased by the Selfridges Group in 2014. BT&A sell quality brands and host class events which're some craic for shopaholics, but their stores are a teensy bit extravagent (at least as my friend Thomas says).\""
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_file=open('new-text-file.txt')\n",
    "new_text_from_file=text_file.read()\n",
    "new_text_from_file=\"Brown Thomas and Arnotts (BTA) are too Irish companies, operating 7 physical shops, which were purchased by the Selfridges Group in 2014. BT&A sell quality brands and host class events which're some craic for shopaholics, but their stores are a teensy bit extravagent (at least as my friend Thomas says).\"\n",
    "new_text_from_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "378b03c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brown', 'thoma', 'and', 'arnott', '(', 'bta', ')', 'are', 'too', 'irish', 'compani', ',', 'oper', '7', 'physic', 'shop', ',', 'which', 'were', 'purchas', 'by', 'the', 'selfridg', 'group', 'in', '2014', '.', 'bt', '&', 'a', 'sell', 'qualiti', 'brand', 'and', 'host', 'class', 'event', 'which', \"'re\", 'some', 'craic', 'for', 'shopahol', ',', 'but', 'their', 'store', 'are', 'a', 'teensi', 'bit', 'extravag', '(', 'at', 'least', 'as', 'my', 'friend', 'thoma', 'say', ')', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens=nltk.word_tokenize(new_text_from_file)\n",
    "stemmer=nltk.stem.porter.PorterStemmer()\n",
    "new_token=[]\n",
    "for word in tokens:\n",
    "    new_token+=[stemmer.stem(word)]\n",
    "print(new_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c409de94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Brown', 'Thomas', 'and', 'Arnotts', '(', 'BTA', ')', 'are', 'too', 'Irish', 'company', ',', 'operating', '7', 'physical', 'shop', ',', 'which', 'were', 'purchased', 'by', 'the', 'Selfridges', 'Group', 'in', '2014', '.', 'BT', '&', 'A', 'sell', 'quality', 'brand', 'and', 'host', 'class', 'event', 'which', \"'re\", 'some', 'craic', 'for', 'shopaholic', ',', 'but', 'their', 'store', 'are', 'a', 'teensy', 'bit', 'extravagent', '(', 'at', 'least', 'a', 'my', 'friend', 'Thomas', 'say', ')', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens=nltk.word_tokenize(new_text_from_file)\n",
    "WNstemmer=nltk.stem.wordnet.WordNetLemmatizer()\n",
    "wn_new_token=[]\n",
    "for word in tokens:\n",
    "    wn_new_token+=[WNstemmer.lemmatize(word)]\n",
    "print(wn_new_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b3751227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9ec50624",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_list=[]\n",
    "for word_no in range(len(tokens)):\n",
    "    compare_list+=[(tokens[word_no],new_token[word_no],wn_new_token[word_no], tokens[word_no]==new_token[word_no]==wn_new_token[word_no])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3a9eebe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-------------+\n",
      "| Original    | Porter   | Wordnet     |\n",
      "+=============+==========+=============+\n",
      "| Brown       | brown    | Brown       |\n",
      "+-------------+----------+-------------+\n",
      "| Thomas      | thoma    | Thomas      |\n",
      "+-------------+----------+-------------+\n",
      "| Arnotts     | arnott   | Arnotts     |\n",
      "+-------------+----------+-------------+\n",
      "| BTA         | bta      | BTA         |\n",
      "+-------------+----------+-------------+\n",
      "| Irish       | irish    | Irish       |\n",
      "+-------------+----------+-------------+\n",
      "| companies   | compani  | company     |\n",
      "+-------------+----------+-------------+\n",
      "| operating   | oper     | operating   |\n",
      "+-------------+----------+-------------+\n",
      "| physical    | physic   | physical    |\n",
      "+-------------+----------+-------------+\n",
      "| shops       | shop     | shop        |\n",
      "+-------------+----------+-------------+\n",
      "| purchased   | purchas  | purchased   |\n",
      "+-------------+----------+-------------+\n",
      "| Selfridges  | selfridg | Selfridges  |\n",
      "+-------------+----------+-------------+\n",
      "| Group       | group    | Group       |\n",
      "+-------------+----------+-------------+\n",
      "| BT          | bt       | BT          |\n",
      "+-------------+----------+-------------+\n",
      "| A           | a        | A           |\n",
      "+-------------+----------+-------------+\n",
      "| quality     | qualiti  | quality     |\n",
      "+-------------+----------+-------------+\n",
      "| brands      | brand    | brand       |\n",
      "+-------------+----------+-------------+\n",
      "| events      | event    | event       |\n",
      "+-------------+----------+-------------+\n",
      "| shopaholics | shopahol | shopaholic  |\n",
      "+-------------+----------+-------------+\n",
      "| stores      | store    | store       |\n",
      "+-------------+----------+-------------+\n",
      "| teensy      | teensi   | teensy      |\n",
      "+-------------+----------+-------------+\n",
      "| extravagent | extravag | extravagent |\n",
      "+-------------+----------+-------------+\n",
      "| as          | as       | a           |\n",
      "+-------------+----------+-------------+\n",
      "| Thomas      | thoma    | Thomas      |\n",
      "+-------------+----------+-------------+\n",
      "| says        | say      | say         |\n",
      "+-------------+----------+-------------+\n"
     ]
    }
   ],
   "source": [
    " \n",
    "table_data=[]\n",
    "\n",
    "for tup in compare_list:\n",
    "    if tup[3]==False:\n",
    "        table_data+=[(tup[0],tup[1],tup[2])]\n",
    "    \n",
    "# create header\n",
    "head = [\"Original\", \"Porter\",\"Wordnet\",\"Match\"]\n",
    "  \n",
    "# display table\n",
    "print(tabulate(table_data, headers=head, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "12c30345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original\t|\tPorter\t|\tWordNet\n",
      "Brown\t|\tbrown\t|\tBrown\n",
      "Thomas\t|\tthoma\t|\tThomas\n",
      "Arnotts\t|\tarnott\t|\tArnotts\n",
      "BTA\t|\tbta\t|\tBTA\n",
      "Irish\t|\tirish\t|\tIrish\n",
      "companies\t|\tcompani\t|\tcompany\n",
      "operating\t|\toper\t|\toperating\n",
      "physical\t|\tphysic\t|\tphysical\n",
      "shops\t|\tshop\t|\tshop\n",
      "purchased\t|\tpurchas\t|\tpurchased\n",
      "Selfridges\t|\tselfridg\t|\tSelfridges\n",
      "Group\t|\tgroup\t|\tGroup\n",
      "BT\t|\tbt\t|\tBT\n",
      "A\t|\ta\t|\tA\n",
      "quality\t|\tqualiti\t|\tquality\n",
      "brands\t|\tbrand\t|\tbrand\n",
      "events\t|\tevent\t|\tevent\n",
      "shopaholics\t|\tshopahol\t|\tshopaholic\n",
      "stores\t|\tstore\t|\tstore\n",
      "teensy\t|\tteensi\t|\tteensy\n",
      "extravagent\t|\textravag\t|\textravagent\n",
      "as\t|\tas\t|\ta\n",
      "Thomas\t|\tthoma\t|\tThomas\n",
      "says\t|\tsay\t|\tsay\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"{}\\t|\\t{}\\t|\\t{}\"\"\".format('Original','Porter','WordNet'))\n",
    "for tup in compare_list:\n",
    "    if tup[3]==False:\n",
    "        print(\"\"\"{}\\t|       {}      |       {}\"\"\".format(tup[0],tup[1],tup[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9e3629",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
